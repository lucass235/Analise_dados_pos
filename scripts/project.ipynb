{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Integrantes \n",
    "\n",
    "- **Nome:** Lucas dos Santos \n",
    "    - Email: lsar@cin.ufpe.br\n",
    "\n",
    "- **Nome:** Davi da Silva\n",
    "    - Email: dsc6@cin.ufpe.br"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from scipy.io import arff\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carregar o arquivo .arff\n",
    "data, meta = arff.loadarff('../data/speeddating.arff')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função para decodificar valores binários\n",
    "def decode_value(value):\n",
    "    if isinstance(value, bytes):\n",
    "        return value.decode('utf-8')\n",
    "    return value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converter para DataFrame do pandas\n",
    "df = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lucas\\AppData\\Local\\Temp\\ipykernel_8652\\132754000.py:2: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(decode_value)\n"
     ]
    }
   ],
   "source": [
    "# Aplicar a função a todas as células do DataFrame\n",
    "df = df.applymap(decode_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>has_null</th>\n",
       "      <th>wave</th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>age_o</th>\n",
       "      <th>d_age</th>\n",
       "      <th>d_d_age</th>\n",
       "      <th>race</th>\n",
       "      <th>race_o</th>\n",
       "      <th>samerace</th>\n",
       "      <th>...</th>\n",
       "      <th>d_expected_num_interested_in_me</th>\n",
       "      <th>d_expected_num_matches</th>\n",
       "      <th>like</th>\n",
       "      <th>guess_prob_liked</th>\n",
       "      <th>d_like</th>\n",
       "      <th>d_guess_prob_liked</th>\n",
       "      <th>met</th>\n",
       "      <th>decision</th>\n",
       "      <th>decision_o</th>\n",
       "      <th>match</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>female</td>\n",
       "      <td>21.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>[4-6]</td>\n",
       "      <td>Asian/Pacific Islander/Asian-American</td>\n",
       "      <td>European/Caucasian-American</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>[0-3]</td>\n",
       "      <td>[3-5]</td>\n",
       "      <td>7.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>[6-8]</td>\n",
       "      <td>[5-6]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>female</td>\n",
       "      <td>21.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[0-1]</td>\n",
       "      <td>Asian/Pacific Islander/Asian-American</td>\n",
       "      <td>European/Caucasian-American</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>[0-3]</td>\n",
       "      <td>[3-5]</td>\n",
       "      <td>7.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>[6-8]</td>\n",
       "      <td>[5-6]</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>female</td>\n",
       "      <td>21.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[0-1]</td>\n",
       "      <td>Asian/Pacific Islander/Asian-American</td>\n",
       "      <td>Asian/Pacific Islander/Asian-American</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>[0-3]</td>\n",
       "      <td>[3-5]</td>\n",
       "      <td>7.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[6-8]</td>\n",
       "      <td>[0-4]</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>female</td>\n",
       "      <td>21.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>[2-3]</td>\n",
       "      <td>Asian/Pacific Islander/Asian-American</td>\n",
       "      <td>European/Caucasian-American</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>[0-3]</td>\n",
       "      <td>[3-5]</td>\n",
       "      <td>7.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>[6-8]</td>\n",
       "      <td>[5-6]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>female</td>\n",
       "      <td>21.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>[2-3]</td>\n",
       "      <td>Asian/Pacific Islander/Asian-American</td>\n",
       "      <td>Latino/Hispanic American</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>[0-3]</td>\n",
       "      <td>[3-5]</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>[6-8]</td>\n",
       "      <td>[5-6]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 123 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  has_null  wave  gender   age  age_o  d_age d_d_age  \\\n",
       "0        0   1.0  female  21.0   27.0    6.0   [4-6]   \n",
       "1        0   1.0  female  21.0   22.0    1.0   [0-1]   \n",
       "2        1   1.0  female  21.0   22.0    1.0   [0-1]   \n",
       "3        0   1.0  female  21.0   23.0    2.0   [2-3]   \n",
       "4        0   1.0  female  21.0   24.0    3.0   [2-3]   \n",
       "\n",
       "                                    race  \\\n",
       "0  Asian/Pacific Islander/Asian-American   \n",
       "1  Asian/Pacific Islander/Asian-American   \n",
       "2  Asian/Pacific Islander/Asian-American   \n",
       "3  Asian/Pacific Islander/Asian-American   \n",
       "4  Asian/Pacific Islander/Asian-American   \n",
       "\n",
       "                                  race_o samerace  ...  \\\n",
       "0            European/Caucasian-American        0  ...   \n",
       "1            European/Caucasian-American        0  ...   \n",
       "2  Asian/Pacific Islander/Asian-American        1  ...   \n",
       "3            European/Caucasian-American        0  ...   \n",
       "4               Latino/Hispanic American        0  ...   \n",
       "\n",
       "   d_expected_num_interested_in_me  d_expected_num_matches like  \\\n",
       "0                            [0-3]                   [3-5]  7.0   \n",
       "1                            [0-3]                   [3-5]  7.0   \n",
       "2                            [0-3]                   [3-5]  7.0   \n",
       "3                            [0-3]                   [3-5]  7.0   \n",
       "4                            [0-3]                   [3-5]  6.0   \n",
       "\n",
       "  guess_prob_liked d_like  d_guess_prob_liked  met  decision  decision_o  \\\n",
       "0              6.0  [6-8]               [5-6]  0.0         1           0   \n",
       "1              5.0  [6-8]               [5-6]  1.0         1           0   \n",
       "2              NaN  [6-8]               [0-4]  1.0         1           1   \n",
       "3              6.0  [6-8]               [5-6]  0.0         1           1   \n",
       "4              6.0  [6-8]               [5-6]  0.0         1           1   \n",
       "\n",
       "   match  \n",
       "0      0  \n",
       "1      0  \n",
       "2      1  \n",
       "3      1  \n",
       "4      1  \n",
       "\n",
       "[5 rows x 123 columns]"
      ]
     },
     "execution_count": 247,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('../data/speeddating.csv', index=False, sep=';')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparação dos dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Tratamento de valores faltantes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. *Verificar o Tipo de Dados*: Identificar as colunas com valores ausentes e verificar o tipo de dados para determinar o melhor método de preenchimento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "age                                95\n",
      "age_o                             104\n",
      "importance_same_race               79\n",
      "importance_same_religion           79\n",
      "pref_o_attractive                  89\n",
      "pref_o_sincere                     89\n",
      "pref_o_intelligence                89\n",
      "pref_o_funny                       98\n",
      "pref_o_ambitious                  107\n",
      "pref_o_shared_interests           129\n",
      "attractive_o                      212\n",
      "sinsere_o                         287\n",
      "intelligence_o                    306\n",
      "funny_o                           360\n",
      "ambitous_o                        722\n",
      "shared_interests_o               1076\n",
      "attractive_important               79\n",
      "sincere_important                  79\n",
      "intellicence_important             79\n",
      "funny_important                    89\n",
      "ambtition_important                99\n",
      "shared_interests_important        121\n",
      "attractive                        105\n",
      "sincere                           105\n",
      "intelligence                      105\n",
      "funny                             105\n",
      "ambition                          105\n",
      "attractive_partner                202\n",
      "sincere_partner                   277\n",
      "intelligence_partner              296\n",
      "funny_partner                     350\n",
      "ambition_partner                  712\n",
      "shared_interests_partner         1067\n",
      "sports                             79\n",
      "tvsports                           79\n",
      "exercise                           79\n",
      "dining                             79\n",
      "museums                            79\n",
      "art                                79\n",
      "hiking                             79\n",
      "gaming                             79\n",
      "clubbing                           79\n",
      "reading                            79\n",
      "tv                                 79\n",
      "theater                            79\n",
      "movies                             79\n",
      "concerts                           79\n",
      "music                              79\n",
      "shopping                           79\n",
      "yoga                               79\n",
      "interests_correlate               158\n",
      "expected_happy_with_sd_people     101\n",
      "expected_num_interested_in_me    6578\n",
      "expected_num_matches             1173\n",
      "like                              240\n",
      "guess_prob_liked                  309\n",
      "met                               375\n",
      "dtype: int64\n",
      "has_null               object\n",
      "wave                  float64\n",
      "gender                 object\n",
      "age                   float64\n",
      "age_o                 float64\n",
      "                       ...   \n",
      "d_guess_prob_liked     object\n",
      "met                   float64\n",
      "decision               object\n",
      "decision_o             object\n",
      "match                  object\n",
      "Length: 123, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Verificar colunas com valores ausentes e seus tipos de dados\n",
    "missing_data = df.isnull().sum()\n",
    "print(missing_data[missing_data > 0]) # Colunas com valores ausentes\n",
    "print(df.dtypes) # Tipos de dados das colunas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. *Preenchimento das Variáveis Numéricas*: Preencher as variáveis numéricas com a média ou mediana. nosso caso vamos usar a mediana, pois ela é menos sensível a outliers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- foi verificado que existe colunas com intervalos de valores, vamos tratar essas colunas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função para converter intervalo de string para valor médio\n",
    "def convert_interval_to_mean(value):\n",
    "    if isinstance(value, str) and '-' in value:\n",
    "        try:\n",
    "            # Remove colchetes e divide o intervalo\n",
    "            parts = value.strip('[]').split('-')\n",
    "            # Lida com valores negativos adequadamente ao identificar o primeiro elemento vazio\n",
    "            if parts[0] == '':  # Caso o valor seja negativo (por exemplo, [-1-0])\n",
    "                low, high = -float(parts[1]), float(parts[2])\n",
    "            else:\n",
    "                low, high = float(parts[0]), float(parts[1])\n",
    "            # Calcula a média\n",
    "            return (low + high) / 2\n",
    "        except ValueError:\n",
    "            return value  # Retorna o valor original se não puder ser convertido\n",
    "    return value  # Retorna o valor original se não for intervalo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "# Função para verificar se uma coluna contém valores no formato de intervalo\n",
    "def is_interval(value):\n",
    "    return bool(re.match(r'\\[\\d+-\\d+\\]', str(value)))\n",
    "\n",
    "# Lista para armazenar os nomes das colunas com valores de intervalo\n",
    "interval_columns = []\n",
    "\n",
    "# Iterar sobre as colunas do DataFrame\n",
    "for column in df.columns:\n",
    "    # Verificar se a coluna contém valores de intervalo\n",
    "    if df[column].apply(is_interval).any():\n",
    "        interval_columns.append(column)\n",
    "\n",
    "interval_columns.append('d_interests_correlate')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aplicar a função nas colunas com intervalos\n",
    "for col in interval_columns:\n",
    "    df[col] = df[col].apply(convert_interval_to_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>wave</th>\n",
       "      <th>age</th>\n",
       "      <th>age_o</th>\n",
       "      <th>d_age</th>\n",
       "      <th>d_d_age</th>\n",
       "      <th>importance_same_race</th>\n",
       "      <th>importance_same_religion</th>\n",
       "      <th>d_importance_same_race</th>\n",
       "      <th>d_importance_same_religion</th>\n",
       "      <th>pref_o_attractive</th>\n",
       "      <th>...</th>\n",
       "      <th>expected_num_interested_in_me</th>\n",
       "      <th>expected_num_matches</th>\n",
       "      <th>d_expected_happy_with_sd_people</th>\n",
       "      <th>d_expected_num_interested_in_me</th>\n",
       "      <th>d_expected_num_matches</th>\n",
       "      <th>like</th>\n",
       "      <th>guess_prob_liked</th>\n",
       "      <th>d_like</th>\n",
       "      <th>d_guess_prob_liked</th>\n",
       "      <th>met</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3.5</td>\n",
       "      <td>35.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>5.5</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3.5</td>\n",
       "      <td>60.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>5.5</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3.5</td>\n",
       "      <td>19.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3.5</td>\n",
       "      <td>30.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>5.5</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3.5</td>\n",
       "      <td>30.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>5.5</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 114 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   wave   age  age_o  d_age  d_d_age  importance_same_race  \\\n",
       "0   1.0  21.0   27.0    6.0      5.0                   2.0   \n",
       "1   1.0  21.0   22.0    1.0      0.5                   2.0   \n",
       "2   1.0  21.0   22.0    1.0      0.5                   2.0   \n",
       "3   1.0  21.0   23.0    2.0      2.5                   2.0   \n",
       "4   1.0  21.0   24.0    3.0      2.5                   2.0   \n",
       "\n",
       "   importance_same_religion  d_importance_same_race  \\\n",
       "0                       4.0                     3.5   \n",
       "1                       4.0                     3.5   \n",
       "2                       4.0                     3.5   \n",
       "3                       4.0                     3.5   \n",
       "4                       4.0                     3.5   \n",
       "\n",
       "   d_importance_same_religion  pref_o_attractive  ...  \\\n",
       "0                         3.5               35.0  ...   \n",
       "1                         3.5               60.0  ...   \n",
       "2                         3.5               19.0  ...   \n",
       "3                         3.5               30.0  ...   \n",
       "4                         3.5               30.0  ...   \n",
       "\n",
       "   expected_num_interested_in_me  expected_num_matches  \\\n",
       "0                            2.0                   4.0   \n",
       "1                            2.0                   4.0   \n",
       "2                            2.0                   4.0   \n",
       "3                            2.0                   4.0   \n",
       "4                            2.0                   4.0   \n",
       "\n",
       "   d_expected_happy_with_sd_people  d_expected_num_interested_in_me  \\\n",
       "0                              2.0                              1.5   \n",
       "1                              2.0                              1.5   \n",
       "2                              2.0                              1.5   \n",
       "3                              2.0                              1.5   \n",
       "4                              2.0                              1.5   \n",
       "\n",
       "   d_expected_num_matches  like  guess_prob_liked  d_like  d_guess_prob_liked  \\\n",
       "0                     4.0   7.0               6.0     7.0                 5.5   \n",
       "1                     4.0   7.0               5.0     7.0                 5.5   \n",
       "2                     4.0   7.0               NaN     7.0                 2.0   \n",
       "3                     4.0   7.0               6.0     7.0                 5.5   \n",
       "4                     4.0   6.0               6.0     7.0                 5.5   \n",
       "\n",
       "   met  \n",
       "0  0.0  \n",
       "1  1.0  \n",
       "2  1.0  \n",
       "3  0.0  \n",
       "4  0.0  \n",
       "\n",
       "[5 rows x 114 columns]"
      ]
     },
     "execution_count": 253,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.select_dtypes(include='number').head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Visto que tem colunas com tipos de dados errados vamos corrigir esses tipos de dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['d_interests_correlate'] = df['d_interests_correlate'].astype(float)\n",
    "df['decision'] = df['decision'].astype(int)\n",
    "df['decision_o'] = df['decision_o'].astype(int)\n",
    "df['match'] = df['match'].astype(int)\n",
    "df['samerace'] = df['samerace'].astype(int)\n",
    "df['has_null'] = df.isnull().any(axis=1).astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Agora podemos prosseguir com o preenchimento dos valores faltantes na categoria de variáveis numéricas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "has_null              0\n",
      "wave                  0\n",
      "age                   0\n",
      "age_o                 0\n",
      "d_age                 0\n",
      "                     ..\n",
      "d_guess_prob_liked    0\n",
      "met                   0\n",
      "decision              0\n",
      "decision_o            0\n",
      "match                 0\n",
      "Length: 119, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Preenchendo valores numéricos com a mediana\n",
    "num_columns = df.select_dtypes(include=['float64', 'int64', 'number']).columns\n",
    "for col in num_columns:\n",
    "    df[col] = df[col].fillna(df[col].median()) # Preencher com a mediana\n",
    "\n",
    "print(df[num_columns].isnull().sum()) # Verificar se ainda existem valores ausentes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. *Preenchimento das Variáveis Categóricas*: Preencher as variáveis categóricas com o valor mais frequente, ou seja, a moda."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gender    0\n",
      "race      0\n",
      "race_o    0\n",
      "field     0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Preenchendo valores categóricos com a moda\n",
    "cat_columns = df.select_dtypes(include=['object']).columns\n",
    "for col in cat_columns:\n",
    "    df[col] = df[col].fillna(df[col].mode()[0])\n",
    "    \n",
    "print(df[cat_columns].isnull().sum()) # Verificar se ainda existem valores ausentes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>has_null</th>\n",
       "      <th>wave</th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>age_o</th>\n",
       "      <th>d_age</th>\n",
       "      <th>d_d_age</th>\n",
       "      <th>race</th>\n",
       "      <th>race_o</th>\n",
       "      <th>samerace</th>\n",
       "      <th>...</th>\n",
       "      <th>d_expected_num_interested_in_me</th>\n",
       "      <th>d_expected_num_matches</th>\n",
       "      <th>like</th>\n",
       "      <th>guess_prob_liked</th>\n",
       "      <th>d_like</th>\n",
       "      <th>d_guess_prob_liked</th>\n",
       "      <th>met</th>\n",
       "      <th>decision</th>\n",
       "      <th>decision_o</th>\n",
       "      <th>match</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>female</td>\n",
       "      <td>21.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Asian/Pacific Islander/Asian-American</td>\n",
       "      <td>European/Caucasian-American</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>5.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>female</td>\n",
       "      <td>21.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>Asian/Pacific Islander/Asian-American</td>\n",
       "      <td>European/Caucasian-American</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>5.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>female</td>\n",
       "      <td>21.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>Asian/Pacific Islander/Asian-American</td>\n",
       "      <td>Asian/Pacific Islander/Asian-American</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1.5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>female</td>\n",
       "      <td>21.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>Asian/Pacific Islander/Asian-American</td>\n",
       "      <td>European/Caucasian-American</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>5.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>female</td>\n",
       "      <td>21.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>Asian/Pacific Islander/Asian-American</td>\n",
       "      <td>Latino/Hispanic American</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>5.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 123 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   has_null  wave  gender   age  age_o  d_age  d_d_age  \\\n",
       "0         0   1.0  female  21.0   27.0    6.0      5.0   \n",
       "1         0   1.0  female  21.0   22.0    1.0      0.5   \n",
       "2         1   1.0  female  21.0   22.0    1.0      0.5   \n",
       "3         0   1.0  female  21.0   23.0    2.0      2.5   \n",
       "4         0   1.0  female  21.0   24.0    3.0      2.5   \n",
       "\n",
       "                                    race  \\\n",
       "0  Asian/Pacific Islander/Asian-American   \n",
       "1  Asian/Pacific Islander/Asian-American   \n",
       "2  Asian/Pacific Islander/Asian-American   \n",
       "3  Asian/Pacific Islander/Asian-American   \n",
       "4  Asian/Pacific Islander/Asian-American   \n",
       "\n",
       "                                  race_o  samerace  ...  \\\n",
       "0            European/Caucasian-American         0  ...   \n",
       "1            European/Caucasian-American         0  ...   \n",
       "2  Asian/Pacific Islander/Asian-American         1  ...   \n",
       "3            European/Caucasian-American         0  ...   \n",
       "4               Latino/Hispanic American         0  ...   \n",
       "\n",
       "   d_expected_num_interested_in_me  d_expected_num_matches  like  \\\n",
       "0                              1.5                     4.0   7.0   \n",
       "1                              1.5                     4.0   7.0   \n",
       "2                              1.5                     4.0   7.0   \n",
       "3                              1.5                     4.0   7.0   \n",
       "4                              1.5                     4.0   6.0   \n",
       "\n",
       "   guess_prob_liked d_like  d_guess_prob_liked  met  decision  decision_o  \\\n",
       "0               6.0    7.0                 5.5  0.0         1           0   \n",
       "1               5.0    7.0                 5.5  1.0         1           0   \n",
       "2               5.0    7.0                 2.0  1.0         1           1   \n",
       "3               6.0    7.0                 5.5  0.0         1           1   \n",
       "4               6.0    7.0                 5.5  0.0         1           1   \n",
       "\n",
       "   match  \n",
       "0      0  \n",
       "1      0  \n",
       "2      1  \n",
       "3      1  \n",
       "4      1  \n",
       "\n",
       "[5 rows x 123 columns]"
      ]
     },
     "execution_count": 257,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Foi identificado algumas colunas com valores do tipo intervalo com isso tratarmos essas colunas para que possamos preencher os valores faltantes, as colunas foram convertidas para o tipo de dados numéricos.\n",
    "\n",
    "- o preenchimento dos valores faltantes foi feito com a moda das colunas para as variáveis categóricas e com a mediana para as variáveis numéricas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Conversão de Tipos de Dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Ja anteriormente foi feito a conversão de algumas colunas para o tipo de dados numéricos, agora vamos converter as colunas  de object para category."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_columns\n",
    "\n",
    "df[cat_columns] = df[cat_columns].astype('category')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-  As variáveis do tipo object foram convertidas para o tipo category para otimizar o uso de memória e facilitar a análise de variáveis categóricas. Essa decisão permite uma manipulação mais eficiente dos dados nas próximas etapas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Tratamento de Outliers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Vamos identificar e tratar os outliers das variáveis numéricas, para isso vamos usar o método IQR (Interquartile Range) para identificar e remover os outliers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['has_null', 'wave', 'age', 'age_o', 'd_age', 'd_d_age', 'samerace',\n",
       "       'importance_same_race', 'importance_same_religion',\n",
       "       'd_importance_same_race',\n",
       "       ...\n",
       "       'd_expected_num_interested_in_me', 'd_expected_num_matches', 'like',\n",
       "       'guess_prob_liked', 'd_like', 'd_guess_prob_liked', 'met', 'decision',\n",
       "       'decision_o', 'match'],\n",
       "      dtype='object', length=119)"
      ]
     },
     "execution_count": 259,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função para identificar e tratar outliers\n",
    "def treat_outliers(df, column):\n",
    "    # Calcula o primeiro e terceiro quartil (Q1 e Q3)\n",
    "    Q1 = df[column].quantile(0.25)\n",
    "    Q3 = df[column].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    \n",
    "    # Define limites superior e inferior\n",
    "    lower_bound = Q1 - 1.5 * IQR\n",
    "    upper_bound = Q3 + 1.5 * IQR\n",
    "    \n",
    "    # Remoção de outliers (opcional)\n",
    "    # df = df[(df[column] >= lower_bound) & (df[column] <= upper_bound)]\n",
    "    \n",
    "    # Substituição de outliers pelo limite superior/inferior\n",
    "    df[column] = df[column].apply(lambda x: upper_bound if x > upper_bound else (lower_bound if x < lower_bound else x))\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       has_null         wave          age        age_o        d_age  \\\n",
      "count    8378.0  8378.000000  8378.000000  8378.000000  8378.000000   \n",
      "mean        1.0    11.350919    26.281213    26.286823     3.750895   \n",
      "std         0.0     5.995903     3.294641     3.289388     2.931862   \n",
      "min         1.0     1.000000    18.000000    18.000000     0.000000   \n",
      "25%         1.0     7.000000    24.000000    24.000000     1.000000   \n",
      "50%         1.0    11.000000    26.000000    26.000000     3.000000   \n",
      "75%         1.0    15.000000    28.000000    28.000000     5.000000   \n",
      "max         1.0    21.000000    34.000000    34.000000    11.000000   \n",
      "\n",
      "           d_d_age     samerace  importance_same_race  \\\n",
      "count  8378.000000  8378.000000           8378.000000   \n",
      "mean      4.237199     0.395799              3.777393   \n",
      "std       3.790632     0.489051              2.833273   \n",
      "min       0.500000     0.000000              0.000000   \n",
      "25%       0.500000     0.000000              1.000000   \n",
      "50%       2.500000     0.000000              3.000000   \n",
      "75%       5.000000     1.000000              6.000000   \n",
      "max      11.750000     1.000000             10.000000   \n",
      "\n",
      "       importance_same_religion  d_importance_same_race  ...  \\\n",
      "count               8378.000000             8378.000000  ...   \n",
      "mean                   3.645500                3.750119  ...   \n",
      "std                    2.792688                2.968501  ...   \n",
      "min                    1.000000                0.500000  ...   \n",
      "25%                    1.000000                0.500000  ...   \n",
      "50%                    3.000000                3.500000  ...   \n",
      "75%                    6.000000                8.000000  ...   \n",
      "max                   10.000000                8.000000  ...   \n",
      "\n",
      "       d_expected_num_interested_in_me  d_expected_num_matches         like  \\\n",
      "count                           8378.0             8378.000000  8378.000000   \n",
      "mean                               1.5                2.901408     6.145285   \n",
      "std                                0.0                2.443966     1.775464   \n",
      "min                                1.5                1.000000     2.000000   \n",
      "25%                                1.5                1.000000     5.000000   \n",
      "50%                                1.5                1.000000     6.000000   \n",
      "75%                                1.5                4.000000     7.000000   \n",
      "max                                1.5                8.500000    10.000000   \n",
      "\n",
      "       guess_prob_liked       d_like  d_guess_prob_liked     met     decision  \\\n",
      "count       8378.000000  8378.000000         8378.000000  8378.0  8378.000000   \n",
      "mean           5.199869     5.599845            5.062664     0.0     0.419909   \n",
      "std            2.090285     2.368298            2.553220     0.0     0.493573   \n",
      "min            0.000000     2.500000            2.000000     0.0     0.000000   \n",
      "25%            4.000000     2.500000            2.000000     0.0     0.000000   \n",
      "50%            5.000000     7.000000            5.500000     0.0     0.000000   \n",
      "75%            7.000000     7.000000            8.500000     0.0     1.000000   \n",
      "max           10.000000     9.500000            8.500000     0.0     1.000000   \n",
      "\n",
      "        decision_o   match  \n",
      "count  8378.000000  8378.0  \n",
      "mean      0.419551     0.0  \n",
      "std       0.493515     0.0  \n",
      "min       0.000000     0.0  \n",
      "25%       0.000000     0.0  \n",
      "50%       0.000000     0.0  \n",
      "75%       1.000000     0.0  \n",
      "max       1.000000     0.0  \n",
      "\n",
      "[8 rows x 119 columns]\n"
     ]
    }
   ],
   "source": [
    "# Aplicar o tratamento de outliers em todas as colunas numéricas\n",
    "for col in num_columns:\n",
    "    df = treat_outliers(df, col)\n",
    "\n",
    "# Verificação do resultado\n",
    "print(df.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Para tratar outliers em todas as colunas numéricas, aplicamos a regra do intervalo interquartil (IQR), que identifica valores extremos fora do intervalo Q1 − 1.5 ∗ IQR, Q3 + 1.5 ∗ IQR. Decidimos substituir esses valores pelo limite superior ou inferior do IQR, preservando assim o número de amostras na base. Essa abordagem assegura que valores extremos não distorçam a análise e a modelagem, mantendo a integridade do conjunto de dados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>has_null</th>\n",
       "      <th>wave</th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>age_o</th>\n",
       "      <th>d_age</th>\n",
       "      <th>d_d_age</th>\n",
       "      <th>race</th>\n",
       "      <th>race_o</th>\n",
       "      <th>samerace</th>\n",
       "      <th>...</th>\n",
       "      <th>d_expected_num_interested_in_me</th>\n",
       "      <th>d_expected_num_matches</th>\n",
       "      <th>like</th>\n",
       "      <th>guess_prob_liked</th>\n",
       "      <th>d_like</th>\n",
       "      <th>d_guess_prob_liked</th>\n",
       "      <th>met</th>\n",
       "      <th>decision</th>\n",
       "      <th>decision_o</th>\n",
       "      <th>match</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>female</td>\n",
       "      <td>21.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Asian/Pacific Islander/Asian-American</td>\n",
       "      <td>European/Caucasian-American</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>5.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>female</td>\n",
       "      <td>21.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>Asian/Pacific Islander/Asian-American</td>\n",
       "      <td>European/Caucasian-American</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>5.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>female</td>\n",
       "      <td>21.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>Asian/Pacific Islander/Asian-American</td>\n",
       "      <td>Asian/Pacific Islander/Asian-American</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1.5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>female</td>\n",
       "      <td>21.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>Asian/Pacific Islander/Asian-American</td>\n",
       "      <td>European/Caucasian-American</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>5.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>female</td>\n",
       "      <td>21.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>Asian/Pacific Islander/Asian-American</td>\n",
       "      <td>Latino/Hispanic American</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>5.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 123 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   has_null  wave  gender   age  age_o  d_age  d_d_age  \\\n",
       "0       1.0   1.0  female  21.0   27.0    6.0      5.0   \n",
       "1       1.0   1.0  female  21.0   22.0    1.0      0.5   \n",
       "2       1.0   1.0  female  21.0   22.0    1.0      0.5   \n",
       "3       1.0   1.0  female  21.0   23.0    2.0      2.5   \n",
       "4       1.0   1.0  female  21.0   24.0    3.0      2.5   \n",
       "\n",
       "                                    race  \\\n",
       "0  Asian/Pacific Islander/Asian-American   \n",
       "1  Asian/Pacific Islander/Asian-American   \n",
       "2  Asian/Pacific Islander/Asian-American   \n",
       "3  Asian/Pacific Islander/Asian-American   \n",
       "4  Asian/Pacific Islander/Asian-American   \n",
       "\n",
       "                                  race_o  samerace  ...  \\\n",
       "0            European/Caucasian-American         0  ...   \n",
       "1            European/Caucasian-American         0  ...   \n",
       "2  Asian/Pacific Islander/Asian-American         1  ...   \n",
       "3            European/Caucasian-American         0  ...   \n",
       "4               Latino/Hispanic American         0  ...   \n",
       "\n",
       "   d_expected_num_interested_in_me  d_expected_num_matches  like  \\\n",
       "0                              1.5                     4.0   7.0   \n",
       "1                              1.5                     4.0   7.0   \n",
       "2                              1.5                     4.0   7.0   \n",
       "3                              1.5                     4.0   7.0   \n",
       "4                              1.5                     4.0   6.0   \n",
       "\n",
       "   guess_prob_liked d_like  d_guess_prob_liked  met  decision  decision_o  \\\n",
       "0               6.0    7.0                 5.5  0.0         1           0   \n",
       "1               5.0    7.0                 5.5  0.0         1           0   \n",
       "2               5.0    7.0                 2.0  0.0         1           1   \n",
       "3               6.0    7.0                 5.5  0.0         1           1   \n",
       "4               6.0    7.0                 5.5  0.0         1           1   \n",
       "\n",
       "   match  \n",
       "0    0.0  \n",
       "1    0.0  \n",
       "2    0.0  \n",
       "3    0.0  \n",
       "4    0.0  \n",
       "\n",
       "[5 rows x 123 columns]"
      ]
     },
     "execution_count": 262,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Criação de Novas Variáveis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Vamos criar novas variáveis para melhorar a análise e a modelagem dos dados."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Diferenças Relacionais entre Atributos: Se há pares de variáveis relacionadas entre o participante e o par (ex. age e age_o), podemos criar novas variáveis que representam a diferença entre eles, como uma variável de diferença de idade."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lucas\\AppData\\Local\\Temp\\ipykernel_8652\\1769004418.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['age_difference'] = abs(df['age'] - df['age_o'])\n"
     ]
    }
   ],
   "source": [
    "# 1. Diferença de idade entre participante e par\n",
    "df['age_difference'] = abs(df['age'] - df['age_o'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Transformações em Intervalos ou Binários: Variáveis contínuas podem ser transformadas em categorias para criar segmentos que facilitem a análise. Por exemplo, criar categorias para idade ou atratividade com base em intervalos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lucas\\AppData\\Local\\Temp\\ipykernel_8652\\1872149184.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['age_group'] = pd.cut(df['age'], bins=[18, 25, 35, 50], labels=['18-25', '26-35', '36-50'])\n"
     ]
    }
   ],
   "source": [
    "# 2. Criação de grupos etários\n",
    "df['age_group'] = pd.cut(df['age'], bins=[18, 25, 35, 50], labels=['18-25', '26-35', '36-50'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Interações entre Preferências e Avaliações: Combine variáveis de preferências para entender as interações entre características, como attractive e funny, e se há uma relação combinada que favoreça o \"match\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lucas\\AppData\\Local\\Temp\\ipykernel_8652\\3918463293.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['attractive_funny_interaction'] = df['attractive'] * df['funny']\n"
     ]
    }
   ],
   "source": [
    "# 3. Interação entre atratividade e diversão\n",
    "df['attractive_funny_interaction'] = df['attractive'] * df['funny']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Criação de Novas Variáveis\n",
    "\n",
    "- Para enriquecer o conjunto de dados e explorar interações complexas que podem impactar a análise e modelagem foi feito a criação dessas novas variáveis:\n",
    "\n",
    "1. Diferença de Idade: Criamos uma variável que mede a diferença de idade entre o participante e o par, o que pode indicar preferências relacionadas a idade.\n",
    "\n",
    "2. Grupos Etários: A variável age foi segmentada em grupos etários para facilitar a análise de comportamentos entre diferentes faixas de idade.\n",
    "\n",
    "3. Interação Atratividade e Diversão: Multiplicamos attractive e funny para criar uma variável de interação que explora se a combinação desses fatores aumenta as chances de um match.\n",
    "\n",
    "Essas variáveis novas ajudam a capturar nuances e relações entre os dados que não seriam visíveis individualmente, permitindo insights mais profundos e aumentando o potencial para modelagens preditivas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age_difference</th>\n",
       "      <th>age_group</th>\n",
       "      <th>attractive_funny_interaction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6.0</td>\n",
       "      <td>18-25</td>\n",
       "      <td>48.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>18-25</td>\n",
       "      <td>48.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>18-25</td>\n",
       "      <td>48.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.0</td>\n",
       "      <td>18-25</td>\n",
       "      <td>48.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.0</td>\n",
       "      <td>18-25</td>\n",
       "      <td>48.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8373</th>\n",
       "      <td>1.0</td>\n",
       "      <td>18-25</td>\n",
       "      <td>56.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8374</th>\n",
       "      <td>1.0</td>\n",
       "      <td>18-25</td>\n",
       "      <td>56.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8375</th>\n",
       "      <td>4.0</td>\n",
       "      <td>18-25</td>\n",
       "      <td>56.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8376</th>\n",
       "      <td>3.0</td>\n",
       "      <td>18-25</td>\n",
       "      <td>56.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8377</th>\n",
       "      <td>3.0</td>\n",
       "      <td>18-25</td>\n",
       "      <td>56.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8378 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      age_difference age_group  attractive_funny_interaction\n",
       "0                6.0     18-25                          48.0\n",
       "1                1.0     18-25                          48.0\n",
       "2                1.0     18-25                          48.0\n",
       "3                2.0     18-25                          48.0\n",
       "4                3.0     18-25                          48.0\n",
       "...              ...       ...                           ...\n",
       "8373             1.0     18-25                          56.0\n",
       "8374             1.0     18-25                          56.0\n",
       "8375             4.0     18-25                          56.0\n",
       "8376             3.0     18-25                          56.0\n",
       "8377             3.0     18-25                          56.0\n",
       "\n",
       "[8378 rows x 3 columns]"
      ]
     },
     "execution_count": 266,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[['age_difference', 'age_group', 'attractive_funny_interaction']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Normalização e Escalonamento de Variáveis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. *Normalização (Escala de 0 a 1)*: Esta técnica transforma os valores para um intervalo entre 0 e 1, o que é útil quando queremos manter a distribuição relativa dos dados.\n",
    "- Usamos a normalização em dados onde a interpretação em uma escala absoluta não é tão crítica, como attractive, funny, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>attractive</th>\n",
       "      <th>funny</th>\n",
       "      <th>intelligence</th>\n",
       "      <th>ambition</th>\n",
       "      <th>age_difference</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.428571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.071429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.071429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.142857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.214286</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   attractive     funny  intelligence  ambition  age_difference\n",
       "0    0.428571  0.428571      0.666667       0.5        0.428571\n",
       "1    0.428571  0.428571      0.666667       0.5        0.071429\n",
       "2    0.428571  0.428571      0.666667       0.5        0.071429\n",
       "3    0.428571  0.428571      0.666667       0.5        0.142857\n",
       "4    0.428571  0.428571      0.666667       0.5        0.214286"
      ]
     },
     "execution_count": 267,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Identificar colunas numéricas que precisam de normalização\n",
    "columns_to_normalize = ['attractive', 'funny', 'intelligence', 'ambition', 'age_difference']\n",
    "\n",
    "# Inicializar normalizador\n",
    "normalizer = MinMaxScaler()\n",
    "\n",
    "# Aplicar normalização (0 a 1)\n",
    "df[columns_to_normalize] = normalizer.fit_transform(df[columns_to_normalize])\n",
    "\n",
    "df[columns_to_normalize].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. *Padronização (Média 0 e Desvio Padrão 1)*: A padronização transforma os dados para que tenham média zero e desvio padrão igual a um. É útil para variáveis que têm uma distribuição normal e para métodos que requerem dados centrados.\n",
    "\n",
    "- A padronização é geralmente aplicada em variáveis com uma ampla faixa de valores ou quando queremos remover diferenças de escala entre variáveis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>age_o</th>\n",
       "      <th>d_age</th>\n",
       "      <th>d_d_age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.603066</td>\n",
       "      <td>0.216824</td>\n",
       "      <td>0.767171</td>\n",
       "      <td>0.201245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.603066</td>\n",
       "      <td>-1.303306</td>\n",
       "      <td>-0.938332</td>\n",
       "      <td>-0.985963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.603066</td>\n",
       "      <td>-1.303306</td>\n",
       "      <td>-0.938332</td>\n",
       "      <td>-0.985963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1.603066</td>\n",
       "      <td>-0.999280</td>\n",
       "      <td>-0.597231</td>\n",
       "      <td>-0.458315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.603066</td>\n",
       "      <td>-0.695254</td>\n",
       "      <td>-0.256131</td>\n",
       "      <td>-0.458315</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        age     age_o     d_age   d_d_age\n",
       "0 -1.603066  0.216824  0.767171  0.201245\n",
       "1 -1.603066 -1.303306 -0.938332 -0.985963\n",
       "2 -1.603066 -1.303306 -0.938332 -0.985963\n",
       "3 -1.603066 -0.999280 -0.597231 -0.458315\n",
       "4 -1.603066 -0.695254 -0.256131 -0.458315"
      ]
     },
     "execution_count": 268,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "columns_to_standardize = ['age', 'age_o', 'd_age', 'd_d_age']\n",
    "\n",
    "standardizer = StandardScaler()\n",
    "\n",
    "# Aplicar padronização (média 0 e desvio padrão 1)\n",
    "df[columns_to_standardize] = standardizer.fit_transform(df[columns_to_standardize])\n",
    "\n",
    "df[columns_to_standardize].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para garantir que as variáveis numéricas estejam na mesma escala e melhorar o desempenho de modelos que são sensíveis a escalas, aplicamos duas técnicas principais:\n",
    "\n",
    "1. Normalização: Transformamos as variáveis attractive, funny, intelligence, ambition e age_difference para um intervalo entre 0 e 1. Isso preserva a distribuição relativa dos valores e facilita a interpretação ao manter todas as variáveis dentro de um intervalo fixo.\n",
    "\n",
    "2. Padronização: A variável age foi padronizada para ter média 0 e desvio padrão 1. Esse método é particularmente útil para variáveis que têm ampla faixa de valores e para assegurar que diferenças de escala não influenciem os resultados.\n",
    "\n",
    "Essas transformações ajudam a evitar que variáveis com amplitudes maiores dominem o modelo e facilitam o uso de algoritmos baseados em distância, garantindo uma análise consistente e equilibrada entre as variáveis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>has_null</th>\n",
       "      <th>wave</th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>age_o</th>\n",
       "      <th>d_age</th>\n",
       "      <th>d_d_age</th>\n",
       "      <th>race</th>\n",
       "      <th>race_o</th>\n",
       "      <th>samerace</th>\n",
       "      <th>...</th>\n",
       "      <th>guess_prob_liked</th>\n",
       "      <th>d_like</th>\n",
       "      <th>d_guess_prob_liked</th>\n",
       "      <th>met</th>\n",
       "      <th>decision</th>\n",
       "      <th>decision_o</th>\n",
       "      <th>match</th>\n",
       "      <th>age_difference</th>\n",
       "      <th>age_group</th>\n",
       "      <th>attractive_funny_interaction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>female</td>\n",
       "      <td>-1.603066</td>\n",
       "      <td>0.216824</td>\n",
       "      <td>0.767171</td>\n",
       "      <td>0.201245</td>\n",
       "      <td>Asian/Pacific Islander/Asian-American</td>\n",
       "      <td>European/Caucasian-American</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>6.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>5.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>18-25</td>\n",
       "      <td>48.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>female</td>\n",
       "      <td>-1.603066</td>\n",
       "      <td>-1.303306</td>\n",
       "      <td>-0.938332</td>\n",
       "      <td>-0.985963</td>\n",
       "      <td>Asian/Pacific Islander/Asian-American</td>\n",
       "      <td>European/Caucasian-American</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>5.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.071429</td>\n",
       "      <td>18-25</td>\n",
       "      <td>48.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>female</td>\n",
       "      <td>-1.603066</td>\n",
       "      <td>-1.303306</td>\n",
       "      <td>-0.938332</td>\n",
       "      <td>-0.985963</td>\n",
       "      <td>Asian/Pacific Islander/Asian-American</td>\n",
       "      <td>Asian/Pacific Islander/Asian-American</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.071429</td>\n",
       "      <td>18-25</td>\n",
       "      <td>48.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>female</td>\n",
       "      <td>-1.603066</td>\n",
       "      <td>-0.999280</td>\n",
       "      <td>-0.597231</td>\n",
       "      <td>-0.458315</td>\n",
       "      <td>Asian/Pacific Islander/Asian-American</td>\n",
       "      <td>European/Caucasian-American</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>6.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>5.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>18-25</td>\n",
       "      <td>48.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>female</td>\n",
       "      <td>-1.603066</td>\n",
       "      <td>-0.695254</td>\n",
       "      <td>-0.256131</td>\n",
       "      <td>-0.458315</td>\n",
       "      <td>Asian/Pacific Islander/Asian-American</td>\n",
       "      <td>Latino/Hispanic American</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>6.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>5.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.214286</td>\n",
       "      <td>18-25</td>\n",
       "      <td>48.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 126 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   has_null  wave  gender       age     age_o     d_age   d_d_age  \\\n",
       "0       1.0   1.0  female -1.603066  0.216824  0.767171  0.201245   \n",
       "1       1.0   1.0  female -1.603066 -1.303306 -0.938332 -0.985963   \n",
       "2       1.0   1.0  female -1.603066 -1.303306 -0.938332 -0.985963   \n",
       "3       1.0   1.0  female -1.603066 -0.999280 -0.597231 -0.458315   \n",
       "4       1.0   1.0  female -1.603066 -0.695254 -0.256131 -0.458315   \n",
       "\n",
       "                                    race  \\\n",
       "0  Asian/Pacific Islander/Asian-American   \n",
       "1  Asian/Pacific Islander/Asian-American   \n",
       "2  Asian/Pacific Islander/Asian-American   \n",
       "3  Asian/Pacific Islander/Asian-American   \n",
       "4  Asian/Pacific Islander/Asian-American   \n",
       "\n",
       "                                  race_o  samerace  ...  guess_prob_liked  \\\n",
       "0            European/Caucasian-American         0  ...               6.0   \n",
       "1            European/Caucasian-American         0  ...               5.0   \n",
       "2  Asian/Pacific Islander/Asian-American         1  ...               5.0   \n",
       "3            European/Caucasian-American         0  ...               6.0   \n",
       "4               Latino/Hispanic American         0  ...               6.0   \n",
       "\n",
       "   d_like  d_guess_prob_liked  met decision  decision_o  match  \\\n",
       "0     7.0                 5.5  0.0        1           0    0.0   \n",
       "1     7.0                 5.5  0.0        1           0    0.0   \n",
       "2     7.0                 2.0  0.0        1           1    0.0   \n",
       "3     7.0                 5.5  0.0        1           1    0.0   \n",
       "4     7.0                 5.5  0.0        1           1    0.0   \n",
       "\n",
       "   age_difference  age_group  attractive_funny_interaction  \n",
       "0        0.428571      18-25                          48.0  \n",
       "1        0.071429      18-25                          48.0  \n",
       "2        0.071429      18-25                          48.0  \n",
       "3        0.142857      18-25                          48.0  \n",
       "4        0.214286      18-25                          48.0  \n",
       "\n",
       "[5 rows x 126 columns]"
      ]
     },
     "execution_count": 269,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Codificação de Variáveis Categóricas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- o objetivo é transformar as variáveis categóricas em um formato numérico que possa ser utilizado em modelos de machine learning, já que a maioria dos algoritmos não aceita variáveis do tipo object ou category."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1 One-Hot Encoding:\n",
    "\n",
    "- Transforme cada categoria em uma coluna binária (0 ou 1). Isso é útil para variáveis categóricas com poucas categorias e evita a introdução de ordens onde não há.\n",
    "\n",
    "- Exemplo: A variável gender com categorias \"female\" e \"male\" será transformada em duas colunas (gender_female e gender_male)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['gender', 'race', 'race_o', 'field'], dtype='object')"
      ]
     },
     "execution_count": 270,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>has_null</th>\n",
       "      <th>wave</th>\n",
       "      <th>age</th>\n",
       "      <th>age_o</th>\n",
       "      <th>d_age</th>\n",
       "      <th>d_d_age</th>\n",
       "      <th>samerace</th>\n",
       "      <th>importance_same_race</th>\n",
       "      <th>importance_same_religion</th>\n",
       "      <th>d_importance_same_race</th>\n",
       "      <th>...</th>\n",
       "      <th>field_physics [astrophysics]</th>\n",
       "      <th>field_political science</th>\n",
       "      <th>field_psychology</th>\n",
       "      <th>field_psychology and english</th>\n",
       "      <th>field_social work</th>\n",
       "      <th>field_sociology</th>\n",
       "      <th>field_speech pathology</th>\n",
       "      <th>field_teaching of English</th>\n",
       "      <th>field_theory</th>\n",
       "      <th>field_working</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.603066</td>\n",
       "      <td>0.216824</td>\n",
       "      <td>0.767171</td>\n",
       "      <td>0.201245</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.603066</td>\n",
       "      <td>-1.303306</td>\n",
       "      <td>-0.938332</td>\n",
       "      <td>-0.985963</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.603066</td>\n",
       "      <td>-1.303306</td>\n",
       "      <td>-0.938332</td>\n",
       "      <td>-0.985963</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.603066</td>\n",
       "      <td>-0.999280</td>\n",
       "      <td>-0.597231</td>\n",
       "      <td>-0.458315</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.603066</td>\n",
       "      <td>-0.695254</td>\n",
       "      <td>-0.256131</td>\n",
       "      <td>-0.458315</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 392 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   has_null  wave       age     age_o     d_age   d_d_age  samerace  \\\n",
       "0       1.0   1.0 -1.603066  0.216824  0.767171  0.201245         0   \n",
       "1       1.0   1.0 -1.603066 -1.303306 -0.938332 -0.985963         0   \n",
       "2       1.0   1.0 -1.603066 -1.303306 -0.938332 -0.985963         1   \n",
       "3       1.0   1.0 -1.603066 -0.999280 -0.597231 -0.458315         0   \n",
       "4       1.0   1.0 -1.603066 -0.695254 -0.256131 -0.458315         0   \n",
       "\n",
       "   importance_same_race  importance_same_religion  d_importance_same_race  \\\n",
       "0                   2.0                       4.0                     3.5   \n",
       "1                   2.0                       4.0                     3.5   \n",
       "2                   2.0                       4.0                     3.5   \n",
       "3                   2.0                       4.0                     3.5   \n",
       "4                   2.0                       4.0                     3.5   \n",
       "\n",
       "   ...  field_physics [astrophysics]  field_political science  \\\n",
       "0  ...                         False                    False   \n",
       "1  ...                         False                    False   \n",
       "2  ...                         False                    False   \n",
       "3  ...                         False                    False   \n",
       "4  ...                         False                    False   \n",
       "\n",
       "   field_psychology  field_psychology and english  field_social work  \\\n",
       "0             False                         False              False   \n",
       "1             False                         False              False   \n",
       "2             False                         False              False   \n",
       "3             False                         False              False   \n",
       "4             False                         False              False   \n",
       "\n",
       "   field_sociology  field_speech pathology  field_teaching of English  \\\n",
       "0            False                   False                      False   \n",
       "1            False                   False                      False   \n",
       "2            False                   False                      False   \n",
       "3            False                   False                      False   \n",
       "4            False                   False                      False   \n",
       "\n",
       "   field_theory  field_working  \n",
       "0         False          False  \n",
       "1         False          False  \n",
       "2         False          False  \n",
       "3         False          False  \n",
       "4         False          False  \n",
       "\n",
       "[5 rows x 392 columns]"
      ]
     },
     "execution_count": 271,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Aplicar One-Hot Encoding\n",
    "df = pd.get_dummies(df, columns=cat_columns, drop_first=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Para preparar as variáveis categóricas para modelagem, aplicamos One-Hot Encoding nas variáveis gender, race e field, transformando cada categoria em uma coluna binária. A técnica de One-Hot Encoding foi escolhida para evitar a introdução de uma ordem artificial entre categorias e preservar a relação original dos dados.\n",
    "\n",
    "- Ao utilizar drop_first=True, eliminamos uma categoria de cada variável para evitar multicolinearidade, mantendo a mesma informação. Esse processo é fundamental para garantir que todas as variáveis categóricas estejam em um formato numérico adequado para algoritmos de machine learning.\n",
    "\n",
    "Com essa codificação, a base de dados está pronta para a modelagem, com todas as variáveis em formatos compatíveis para análise quantitativa e predição."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('../data/speeddating_preprocessed.csv', index=False, sep=';')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
